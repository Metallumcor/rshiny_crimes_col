---
title: "Redes neuronales con Keras"
output: 
  html_document:
    standalone: true
    smart: true
    normalize: true
    toc: true
    highlight: tango
    self-contained: true
    theme: cerulean
  pdf_document:
    toc: true
    highlight: tango
always_allow_html: true
vignette: >
  %\VignetteIndexEntry{redes_neuronales_keras}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

### Desarrollo de redes neuronales con Keras

#### Introducción

Es bien sabido que Python es el lenguaje preferido para trabajar con
aprendizaje de maquina e inteligencia artificial, contando con librerías 
reconocidas como TensorFlow y Keras las cuales cuentan con una sintaxis de
fácil aprendizaje y un nivel de personalización alto de sus modelos, la cual
incluye formulación, optimización, predicción, entre otras características. Por 
lo anterior, junto al principio de *no reinventar la rueda* desde 2018 se a 
proporcionado a `R` con una interfaz a TensorFlow+Keras mediante las librerías
homónimas en su lenguaje, es por ello que en el desarrollo del paquete
de pruebas `test2021` no se incluye directamente los modelos proporcionados
por dichos paquetes, considerando en adición el grado de complejidad que
puede alcanzar una red neuronal profunda y sus variantes.

Las librerías de `keras` y `tensorflow` pueden ser instaladas mediante la 
siguiente instrucción

```{r instalacion, eval=FALSE}
install.packages("keras", dependencies = TRUE)
library(keras)
```

```{r instalacion_2, echo=FALSE}
library(keras)
```

Antes de poder trabajar con ellas es necesario disponer de una instalación de 
Python apropiada que incluya dichas librerías. Esto puede hacerse manualmente
o mediante la instrucción siguiente

```{r instalacion_3, eval=FALSE}
keras::install_keras()
```

Al correrla se pedirá al usuario confirmar algunas tareas o llevarlas
a cabo en una terminal. Se debe aclarar que el procedimiento anterior solo
habilitará a Keras para correr en CPU. Las instrucciones de instalación y 
relacionadas para ejecutar tareas mediante procesamiento por GPU pueden
consultarse [acá](https://tensorflow.rstudio.com/installation/gpu/local_gpu/).

#### Modelos propuestos

Para mostrar algunas utilidades de estos paquetes se utilizaran los datos 
de hurtos de bicicletas tratados en la viñeta `clasificacion`, priorizando
el uso del conjunto aumentado por inclusión de rezagos y variables temporales
auxiliares (e.g. los días numerados del primero registrado en adelante). Los
detalles del como se obtuvieron los datos y las motivaciones de los tratamientos
aplicados pueden consultarse en dicha viñeta.

```{r datos, message=FALSE, warning=FALSE, include=FALSE}
require(test2021, quietly = TRUE)
require(dplyr, quietly = TRUE)
PATH <- "D:/R_projects/r_packages/path/work_pkg/test2021"
## Conjunto de datos existentes
bici_db <- lon_hurto_bicicletas
bici_db <- subset(bici_db, select = c(FECHA, CODIGO_DIV1, 
                                       CODIGO_DIV2, SEXO,
                                       RANG_DIA))
## Proporcionalidad por sexo - Tomado de robo de bicis Bogota
df_prop_sexo <- data.frame(
  SEXO = c("FEMENINO", "MASCULINO", "NO REPORTA"),
  PROP = prop.table(c(1579, 6332, 112))
)
## Proporcionalidad por rango del dia - Tomado de robo de bicis Bogota
df_prop_rang_dia <- data.frame(
  RANG_DIA = c("MADRUGADA", "MAÑANA", "TARDE", "NOCHE"),
  PROP = prop.table(c(1868, 2387, 1915, 1791))
)
## Conjunto de datos externo
# Lectura, se realiza por partes
lon_part1 <- read.csv(paste0(PATH,"/extdata/londres_part1.csv"))
lon_part2 <- read.csv(paste0(PATH,"/extdata/londres_part2.csv"))
lon_part3 <- read.csv(paste0(PATH,"/extdata/londres_part3.csv"))
lon_part4 <- read.csv(paste0(PATH,"/extdata/londres_part4.csv"))
# Acoplamiento
lon_full <- dplyr::bind_rows(lon_part1, lon_part2, lon_part3, lon_part4)
# Depurar memoria
rm(lon_part1,  lon_part2, lon_part3, lon_part4)
# Filtar para robo de bicis
lon_filter_bici <- lon_full %>%
  dplyr::filter(Crime.type == "Bicycle theft") %>%
  dplyr::select(Month, Longitude, Latitude)
# Otra depuracion
rm(lon_full)
# Cambiar nombres para acoplar bases
names(lon_filter_bici) <- c("FECHA", "longitude", "latitude")
# Usar solo casos completos
lon_filter_bici <- lon_filter_bici[complete.cases(lon_filter_bici),]
## Procesamiento con las funciones del paquete
# Agregar informacion espacial - Distritos y barrios
lon_filter_bici <- add_spatial_f(lon_filter_bici, londres, "CODIGO_DIV1", "CODIGO_DIV2")
# Agregar informacion de sexo y rango dia
lon_filter_bici <- simular_variables_adicionales(lon_filter_bici, df_prop_sexo = df_prop_sexo,
                                             df_prop_rang_dia = df_prop_rang_dia)
# Sintetizar todo en una sola base de datos
bici_db <- dplyr::bind_rows(lon_filter_bici, bici_db)
# Transformar columna de fecha en Date
bici_db$FECHA <- as.Date(paste0(bici_db$FECHA,"-01"))
# Depuracion
rm(lon_filter_bici)
bici_dt <- data.table::as.data.table(bici_db)
### Se requiere una separacion por distrito, en principio. Completando ceros
db_1a <- as.data.frame(bici_dt[,.N,.(FECHA, CODIGO_DIV1)])
db_1a <- fill_long(db_1a$N, subset(db_1a, select = -N),
                   date_col = "FECHA", time_delta = "1 month")
## 1.2. Normalizacion por densidades
lon_pop <- read.csv(paste0(PATH,"/extdata/londres_pop.csv"))
# Ver los nombres de los distritos
unique(lon_pop$Name)
# Eliminar las agregaciones
agg_cat <- c("London", "Greater London", "Outer London", "Inner London")
lon_pop <- lon_pop[!lon_pop$Name %in% agg_cat,]
# Retener solo campos necesarios
lon_pop <- lon_pop[,c("Name","Year","Population")]
# Obtener los CODIGOS_DIV1
lon_pop <- merge(lon_pop, 
                 unique(londres@data[,c("CODIGO_DIV1", "NOMBRE_DIV1")]), 
                 by.x = "Name", by.y =  "NOMBRE_DIV1")
# Merge con la tabla
db_1a$Year <- format(db_1a$FECHA,"%Y")
db_1a_norm <- merge(db_1a, lon_pop, by = c("CODIGO_DIV1","Year"))
# Corregir poblacion flotante (Tomando 542.000 a 2020 y tasa de 
# crecimiento exponencial constante de 1.35% anual)
db_1a_norm <- db_1a_norm %>%
  mutate(Population = Population + 
           ifelse(Name == "City of London", 
                  506851.2*(1+0.0135)^(as.numeric(Year)-2015),0))
# Tasa de delitos por 100 mil habitantes
db_1a_norm$y <- 100000*db_1a_norm$y/db_1a_norm$Population
db_1a_norm$y <- 100000*db_1a_norm$y/db_1a_norm$Population
### Adicion de lags
# La adicion se realiza considerando todo el conjunto de datos
# Esto no presenta algun problema dado que a futuro asumimos conocidos los
# Conteos pasados (el horizonte de prediccion sera de un paso adelante)
db_1b_norm <- add_laggs(db_1a_norm, db_1a_norm$y, p = 3)
### Adicion de secuencia numerica de seguimiento de fecha
fecha_look <- data.frame(fecha = unique(db_1b_norm$FECHA), 
                         num_fecha = 1:length(unique(db_1b_norm$FECHA)))
db_1b_norm$FECHA_NUM <- fecha_look[match(db_1b_norm$FECHA,fecha_look$fecha),"num_fecha"]
# Renombrar respuesta por conveniencia
db_1b_norm$CLASS <- db_1b_norm$y 
# Drop de variables no requeridas
db_1b_norm <- subset(db_1b_norm, select = c(CODIGO_DIV1, FECHA, CLASS,
                                            Y1, Y2, Y3, FECHA_NUM))
# Tratamiento de fechas
db_1b_norm <- add_date_split(db_1b_norm, "FECHA", 
                             week = FALSE,
                             week_day = FALSE)
db_1b_norm$ANNO <- as.numeric(db_1b_norm$ANNO)
# Crear splits
db_1b_norm$CODIGO_DIV1 <- factor(db_1b_norm$CODIGO_DIV1)
db_1b_norm$MES <- factor(db_1b_norm$MES)
split_class_b <- create_split_long(db_1b_norm$CLASS, 
                                 db_1b_norm[,-2],
                                 factors = "CODIGO_DIV1",
                                 split_prop = c(0.7,0.15,0.15))
### num2ctgr crea los intervalos de acuerdo al metodo (type) seleccionado
### De acuerdo a type, se requieren ciertos argumentos adicionales
## NOTA: Los intervalos pueden variar entre conjuntos de datos por su definicion
## A.1 Intervalos usando cuantiles -> Cuantiles 0.15, 0.5 y 0.8
int_cuantiles_b <- num2ctgr(split_class_b$Y$Y_train, type = "quantiles", 
                            probs = c(0.15, 0.5, 0.8))
### Remplazar los nombres en entrenamiento
niveles <- c("Muy bajo","Bajo","Moderado","Alto")
split_class_b$Y$Y_train <- ctgr2nmd(int_cuantiles_b, niveles)
### Remplazar los nombres en validacion
split_class_b$Y$Y_val <- ctgr2nmd(add2ctgr(split_class_b$Y$Y_val, int_cuantiles_b), niveles)
### Conjuntos escalados usando entrenamiento
split_class_b_std <- split_class_b
num_ind <- sapply(split_class_b$X$X_train, is.numeric)
std_b <- lapply(split_class_b$X$X_train[num_ind], scale)
split_class_b_std$X$X_train[num_ind] <- as.numeric(do.call(cbind, std_b))
mn_b_train <- lapply(std_b, function(x)attr(x,"scaled:center"))
sd_b_train <- lapply(std_b, function(x) attr(x,"scaled:scale"))
split_class_b_std$X$X_val[num_ind] <- 
  mapply(function(x,y,z) (x-y)/z, x = split_class_b_std$X$X_val[num_ind], 
         y = mn_b_train, z = sd_b_train)
```

Para comenzar con los desarrollos se recuerda que el conjunto de datos tiene
122 mil entradas que son divididas en una partición entrenamiento/validación/prueba
de 70% / 15% / 15%, respectivamente, la variable objetivo es de tipo categórica 
la cual corresponde con la propensión de ocurrencias de un hurto (muy bajo, bajo, 
moderado y alto), cada observación esta asociada a un distrito de Londres en un 
mes determinado y poseen un total de 7 características asociadas entre las que 
se incluyen las tasas de hurtos por cada 100 mil habitantes de los últimos tres 
meses a partir de la fecha de registro.

Esta información se encuentra almacenada en el objeto `split_class_b_std`, 
donde en adición las variables de tipo numérico han sido estandarizadas 
(centradas y con varianza 1). Para poder hacer uso de la información
descrita dentro de una red neuronal se precisa un paso adicional, el cual
corresponde con el *encoding* de las variables categóricas lo cual puede
ser realizado mediante la función auxiliar `split_nn` del paquete
`test2021`

```{r split_keras}
split_keras <- split_nn(split_class_b_std)
# Esta es la cantidad de feature pasadas a la red neuronal
ncol(split_keras$X$X_train)
# Y esta es la cantidad de categorias de la respuesta
ncol(split_keras$Y$Y_train)
```
En principio se buscará trabajar con redes neuronales secuenciales con una
o dos capas ocultas totalmente conectadas, cuya cantidad de nodos estará dada
como un número intermedio entre el total de entradas (49) y salidas (4).
Considerando que se va a trabajar en clasificación multi-categoría lo más 
adecuado es utilizar una salida con (función de activación *softmax*)[https://www.r-bloggers.com/2021/04/not-so-soft-softmax/]. Respecto
a las capas intermedias (ocultas) se opta por las funciones de activación
rectificadas (*ReLu*), a diferencia del paquete ``nnet` que utiliza logísticas 
(*sigmoid*)

A continuación se formulan los esqueletos de los modelos a probar

```{r modelos, warning=FALSE, message=FALSE}
## Modelo 1
# Primera capa oculta: Activador relu, 49 nodos
# Segunda capa oculta: Activador relu, [49/2] = 24 nodos
# Output: Softmax

modelo_1 <- keras::keras_model_sequential() %>%
  keras::layer_dense(units = 49, activation = "relu", input_shape = c(49)) %>%
  keras::layer_dense(units = 24, activation = "relu") %>%
  keras::layer_dense(units = 4, activation = "softmax")

## Modelo 2
# Primera capa oculta: Activador relu, 49 nodos
# Segunda capa oculta: Activador relu, [49(3/4)] = 37 nodos
# Output: Softmax

modelo_2 <- keras::keras_model_sequential() %>%
  keras::layer_dense(units = 49, activation = "relu", input_shape = c(49)) %>%
  keras::layer_dense(units = 37, activation = "relu") %>%
  keras::layer_dense(units = 4, activation = "softmax")

## Modelo 3
# El modelo usado por nnet

modelo_3 <- keras::keras_model_sequential() %>%
  keras::layer_dense(units = 4, activation = "sigmoid", input_shape = c(49)) %>%
  keras::layer_dense(units = 4, activation = "softmax")

## Modelo 4
# El modelo usado por nnet pero con mas nodos y activador relu
# Primera capa oculta: Activador relu, 49 nodos
# Output: Softmax

modelo_4 <- keras::keras_model_sequential() %>%
  keras::layer_dense(units = 49, activation = "relu", input_shape = c(49)) %>%
  keras::layer_dense(units = 4, activation = "softmax")

## Modelo 5
# Experimento con tres capas. Cada capa tiene la mitad de la anterior

modelo_5 <- keras::keras_model_sequential() %>%
  keras::layer_dense(units = 49, activation = "relu", input_shape = c(49)) %>%
  keras::layer_dense(units = 24, activation = "relu") %>%
  keras::layer_dense(units = 12, activation = "relu") %>%
  keras::layer_dense(units = 4, activation = "softmax")

## Modelo 6
# Experimento con dos capas. Cada capa tiene la mitad de la anterior
# Se incluye drop-out de 0.4 y 0.3

modelo_6 <- keras::keras_model_sequential() %>%
  keras::layer_dense(units = 49, activation = "relu", input_shape = c(49)) %>%
  keras::layer_dropout(rate = 0.4) %>%
  keras::layer_dense(units = 24, activation = "relu") %>%
  keras::layer_dropout(rate = 0.3) %>%
  keras::layer_dense(units = 4, activation = "softmax")
```

Cada modelo secuencial debe ser iniciado usando `keras_model_sequential`
al cual se le agregan capas densas o totalmente conectadas en su *pipe* 
mediante `layer_dense` donde la primera capa oculta debe contener la
información del tamaño de las entradas. Una ventaja de este tipo de formulación
es que los modelos pueden ser modificados con la adición de nuevas capas
en cualquier momento (previo entrenamiento, idealmente) por como se maneja
Keras en Python. 

Ya con los esqueletos propuestos el siguiente paso es completar el objeto
del modelo para realizar el entrenamiento mediante la especificación
del método de optimización, la función de perdida y la métrica de evaluación.
En este caso se optará por utilizar el optimizador *Adam*, ya que es uno
de los más populares y con mejores resultados a la fecha, junto una
función de perdida de *¨crossentropy* para categorías y la métrica 
*accuracy* en su versión macro, frecuente en problemas de clasificación.

```{r compilar_modelos}
modelo_1 %>%
  compile(
    loss = "categorical_crossentropy",
    optimizer = keras::optimizer_adam(),
    metrics = c("accuracy")
  )

modelo_2 %>%
  compile(
    loss = "categorical_crossentropy",
    optimizer = keras::optimizer_adam(),
    metrics = c("accuracy")
  )

modelo_3 %>%
  compile(
    loss = "categorical_crossentropy",
    optimizer = keras::optimizer_adam(),
    metrics = c("accuracy")
  )

modelo_4 %>%
  compile(
    loss = "categorical_crossentropy",
    optimizer = keras::optimizer_adam(),
    metrics = c("accuracy")
  )

modelo_5 %>%
  compile(
    loss = "categorical_crossentropy",
    optimizer = keras::optimizer_adam(),
    metrics = c("accuracy")
  )

modelo_6 %>%
  compile(
    loss = "categorical_crossentropy",
    optimizer = keras::optimizer_adam(),
    metrics = c("accuracy")
  )
```

Nuevamente se remarcan las diferencias en la escritura en `R` al usar Keras, pues 
no es necesario usar el operador de asignación `<-` para actualizar los
modelos sino que es suficiente el uso del *pipe* `%>%` para ello. De esta misma
forma se entrenan los modelos, en cuyo procesamiento se usarán 200 *epoch* y
lotes de tamaño $2^9$

**Nota:** Se llama `ggplot2` para obtener los gráficos requeridos

```{r lib_graf}
library(ggplot2)
```

```{r modelo_1, warning=FALSE, message=FALSE}
historico_1 <- modelo_1 %>%
  fit(
    split_keras$X$X_train,
    split_keras$Y$Y_train,
    epochs = 200,
    batch_size = 512,
    view_metrics = FALSE,
    validation_data = list(split_keras$X$X_val, split_keras$Y$Y_val)
  )

plot(historico_1)
```

```{r modelo_2, warning=FALSE, message=FALSE}
historico_2 <- modelo_2 %>%
  fit(
    split_keras$X$X_train,
    split_keras$Y$Y_train,
    epochs = 200,
    batch_size = 512,
    view_metrics = FALSE,
    validation_data = list(split_keras$X$X_val, split_keras$Y$Y_val)
  )

plot(historico_2)
```

```{r modelo_3, warning=FALSE, message=FALSE}
historico_3 <- modelo_3 %>%
  fit(
    split_keras$X$X_train,
    split_keras$Y$Y_train,
    epochs = 200,
    batch_size = 512,
    validation_data = list(split_keras$X$X_val, split_keras$Y$Y_val)
  )

plot(historico_3)
```

```{r modelo_4, warning=FALSE, message=FALSE}
historico_4 <- modelo_4 %>%
  fit(
    split_keras$X$X_train,
    split_keras$Y$Y_train,
    epochs = 200,
    batch_size = 512,
    validation_data = list(split_keras$X$X_val, split_keras$Y$Y_val)
  )

plot(historico_4)
```
```{r modelo_5, warning=FALSE, message=FALSE}
historico_5 <- modelo_5 %>%
  fit(
    split_keras$X$X_train,
    split_keras$Y$Y_train,
    epochs = 200,
    batch_size = 512,
    validation_data = list(split_keras$X$X_val, split_keras$Y$Y_val)
  )

plot(historico_5)
```

```{r modelo_6, warning=FALSE, message=FALSE}
historico_6 <- modelo_6 %>%
  fit(
    split_keras$X$X_train,
    split_keras$Y$Y_train,
    epochs = 200,
    batch_size = 512,
    validation_data = list(split_keras$X$X_val, split_keras$Y$Y_val)
  )

plot(historico_6)
```

#### Conclusión

Para finalizar se resumen los modelos mediante múltiples ajustes para medir
la calidad de las redes neuronales mientras se considera la aleatoriedad en 
los pesos asignados. Para lo anterior se propone correr cada modelo 50 veces
fijando una semilla desde la primera iteración de estos y reportando diferentes
medidas de rendimiento durante la validación de cada uno. En adición, 
se utiliza la información sobre la progresión de la función de perdida en los 
históricos del ajuste piloto de cada modelo intentando una parada temprana

```{r conclusion_1, echo = FALSE, eval = FALSE}
### Funciones para correr la simulacion
### Algoritmos para correr modelos multiples veces
# Con una layer
# nn_1hl <- function(split_out,
#                    early_stop = TRUE,
#                    ...){
#   # Parametros globales
#   n_inp <- ncol(split_out$X$X_train)
#   n_out <- ncol(split_out$Y$Y_train)
#   nods_lay1 <- n_inp
#   n_epoch <- 200
#   batch_size <- 512
#   patience <- 5
#   verbose_parm <- 0
#   activ_lay1 <- "relu"
#   # Dots
#   dots <- list(...)
#   list2env(dots, envir = environment())
#   # Configuracion del callback
#   callback_list <- NULL
#   if(early_stop){
#     callback_list <- list(
#       keras::callback_early_stopping(
#         monitor = "accuracy",
#         patience = patience
#       )
#     )
#   }
#   # Modelo
#   model <- keras::keras_model_sequential() %>%
#     keras::layer_dense(units = nods_lay1, activation = activ_lay1, input_shape = c(n_inp)) %>%
#     keras::layer_dense(units = n_out, activation = "softmax") %>%
#     compile(
#       loss = "categorical_crossentropy",
#       optimizer = keras::optimizer_adam(),
#       metrics = c("accuracy")
#     ) 
#   model %>% 
#     fit(
#       split_out$X$X_train,
#       split_out$Y$Y_train,
#       epochs = n_epoch,
#       batch_size = batch_size,
#       view_metrics = FALSE,
#       callbacks = callback_list,
#       verbose = verbose_parm,
#       validation_data = list(split_out$X$X_val, split_out$Y$Y_val)
#     )
#   return(model)
# }
# 
# # Con dos layers
# nn_2hl <- function(split_out,
#                    early_stop = TRUE,
#                    ...){
#   # Parametros globales
#   n_inp <- ncol(split_out$X$X_train)
#   n_out <- ncol(split_out$Y$Y_train)
#   nods_lay1 <- n_inp
#   nods_lay2 <- floor(n_inp/2)
#   n_epoch <- 200
#   batch_size <- 512
#   patience <- 5
#   verbose_parm <- 0
#   rate_1 <- rate_2 <- 0
#   # Dots
#   dots <- list(...)
#   list2env(dots, envir = environment())
#   # Configuracion del callback
#   callback_list <- NULL
#   if(early_stop){
#     callback_list <- list(
#       keras::callback_early_stopping(
#         monitor = "accuracy",
#         patience = patience
#       )
#     )
#   }
#   # Modelo
#   model <- keras::keras_model_sequential() %>%
#     keras::layer_dense(units = nods_lay1, activation = "relu", input_shape = c(n_inp)) %>%
#     keras::layer_dropout(rate = rate_1) %>%
#     keras::layer_dense(units = nods_lay2, activation = "relu") %>%
#         keras::layer_dropout(rate = rate_2) %>%
#     keras::layer_dense(units = n_out, activation = "softmax") %>%
#     compile(
#       loss = "categorical_crossentropy",
#       optimizer = keras::optimizer_adam(),
#       metrics = c("accuracy")
#     ) 
#   model %>% 
#     fit(
#       split_out$X$X_train,
#       split_out$Y$Y_train,
#       epochs = n_epoch,
#       batch_size = batch_size,
#       view_metrics = FALSE,
#       callbacks = callback_list,
#       verbose = verbose_parm,
#       validation_data = list(split_out$X$X_val, split_out$Y$Y_val)
#     )
#   return(model)
# }
# 
# # Con tres layers
# nn_3hl <- function(split_out,
#                    early_stop = TRUE,
#                    ...){
#   # Parametros globales
#   n_inp <- ncol(split_out$X$X_train)
#   n_out <- ncol(split_out$Y$Y_train)
#   nods_lay1 <- n_inp
#   nods_lay2 <- floor(n_inp/2)
#   nods_lay3 <- floor(n_inp/4)
#   n_epoch <- 200
#   batch_size <- 512
#   patience <- 5
#   verbose_parm <- 0
#   # Dots
#   dots <- list(...)
#   list2env(dots, envir = environment())
#   # Configuracion del callback
#   callback_list <- NULL
#   if(early_stop){
#     callback_list <- list(
#       keras::callback_early_stopping(
#         monitor = "accuracy",
#         patience = patience
#       )
#     )
#   }
#   # Modelo
#   model <- keras::keras_model_sequential() %>%
#     keras::layer_dense(units = nods_lay1, activation = "relu", input_shape = c(n_inp)) %>%
#     keras::layer_dense(units = nods_lay2, activation = "relu") %>%
#     keras::layer_dense(units = nods_lay3, activation = "relu") %>%    
#     keras::layer_dense(units = n_out, activation = "softmax") %>%
#     compile(
#       loss = "categorical_crossentropy",
#       optimizer = keras::optimizer_adam(),
#       metrics = c("accuracy")
#     ) 
#   model %>% 
#     fit(
#       split_out$X$X_train,
#       split_out$Y$Y_train,
#       epochs = n_epoch,
#       batch_size = batch_size,
#       view_metrics = FALSE,
#       callbacks = callback_list,
#       verbose = verbose_parm,
#       validation_data = list(split_out$X$X_val, split_out$Y$Y_val)
#     )
#   return(model)
#}
# Los modelos no se pueden guardar...
set.seed(100)
list_models <- list()
list_models$model_1 <- lapply(1:50,function(x)
  nn_2hl(split_class_b_std, n_epoch = 80))
list_models$model_2 <- lapply(1:50, function(x) 
  nn_2hl(split_class_b_std, nods_lay2 = 37, n_epoch =80))
list_models$model_3 <- lapply(1:50, function(x)
  nn_1hl(split_class_b_std,nods_lay1 = 4, activ_lay1 = "sigmoid", n_epoch = 200))
list_models$model_4 <- lapply(1:50, function(x) 
  nn_1hl(split_class_b_std, n_epoch = 80))
list_models$model_5 <- lapply(1:50, function(x) 
  nn_3hl(split_class_b_std, n_epoch = 40))
list_models$model_6 <- lapply(1:50,function(x) 
  nn_1hl(split_class_b_std, n_epoch = 80,rate_1 = 0.4, rate_2 = 0.3))
# Funcion para obtener acc
#acc_cycle <- function(split_mod, split_metr, FUN, n_rep = 1000, ...){
#  # Ppl
#  temp_fun <- function(x){
#    test2021::clsf_metrics(fit = x, split_out = split_metr, metrics_out = "accuracy")
#  }
  # Simu
#  replicate(n = n_rep, temp_fun(FUN(split_out = split_mod, ...))) 
#}
```

##### Accuracy

A continuación una comparación mediante box-plots de los seis modelos estudiados
````{r conclusion_2, echo=FALSE, eval = FALSE}
### Chunk donde se realizan las simulaciones como tal
resultados <- 
  data.frame(modelo_1 = sapply(list_models$model_1,function(x) x$acc_val),
             modelo_2 = sapply(list_models$model_2,function(x) x$acc_val),
             modelo_3 = sapply(list_models$model_3,function(x) x$acc_val),
             modelo_4 = sapply(list_models$model_4,function(x) x$acc_val),
             modelo_5 = sapply(list_models$model_5,function(x) x$acc_val),
             modelo_6 = sapply(list_models$model_6,function(x) x$acc_val)
             )
```

```{r conclusion_3, echo=FALSE}
# carga
resultados <- readRDS(paste0(PATH,"/vignettes/models/res_keras_1.rds"))
colnames(resultados) <- paste("ANN",c("2HL 49/24", "2HL 49/37",
                                      "1HL Sigm 4", "1HL 49",
                                      "3HL 49/24/12", "2HL 49/24 Drop"))
# Grafica
library(reshape2)
resultados %>%
  reshape2::melt() %>%
  ggplot2::ggplot(ggplot2::aes(x = variable, y = value, fill = variable))+
  ggplot2::geom_boxplot() +
  ggplot2::theme_bw() +
  ggplot2::ylab("Accuracy") +
  ggplot2::xlab("") +
  ggplot2::ggtitle("Comparacion de rendimientos") +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust=1))
```

```{r conclusion_3b, echo=FALSE}
# Grafica
resultados %>%
  subset(select = -`ANN 1HL Sigm 4`) %>%
  reshape2::melt() %>%
  ggplot2::ggplot(ggplot2::aes(x = variable, y = value, fill = variable))+
  ggplot2::geom_boxplot() +
  ggplot2::theme_bw() +
  ggplot2::ylab("Accuracy") +
  ggplot2::xlab("") +
  ggplot2::ggtitle("Comparacion de rendimientos") +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust=1))
```

En números, los resultados serían los siguientes

```{r conclusion_4, echo = FALSE}
### Resumenes
data_resumen <- data.frame(Min = unlist(lapply(resultados, min)),
                           Max = unlist(lapply(resultados, max)),
                           Media = unlist(lapply(resultados, mean)),
                           DE = unlist(lapply(resultados, sd)),
                           CV = unlist(
                             lapply(resultados,function(x) 
                               round(100*sd(x)/mean(x),3))))
rownames(data_resumen) <- paste("ANN",c("2HL 49/24", "2HL 49/37",
                                      "1HL Sigm 4", "1HL 49",
                                      "3HL 49/24/12", "2HL 49/24 Drop"))
knitr::kable(data_resumen, digits = 3, row.names = TRUE)
```

##### Adjusted Rand Index

Se comparan nuevamente los modelos usando box-plots

````{r conclusion_5, echo=FALSE, eval = FALSE}
### Chunk donde se realizan las simulaciones como tal
resultados <- 
  data.frame(modelo_1 = sapply(list_models$model_1,function(x)
               clsf_metrics(x$fit,
                            split_class_b_std,"validation","adjusted_rand_index")),
             modelo_2 = sapply(list_models$model_2,function(x)
               clsf_metrics(x$fit,
                            split_class_b_std,"validation","adjusted_rand_index")),
             modelo_3 = sapply(list_models$model_3,function(x)
               clsf_metrics(x$fit,
                            split_class_b_std,"validation","adjusted_rand_index")),
             modelo_4 = sapply(list_models$model_4,function(x)
               clsf_metrics(x$fit,
                            split_class_b_std,"validation","adjusted_rand_index")),
             modelo_5 = sapply(list_models$model_5,function(x)
               clsf_metrics(x$fit,
                            split_class_b_std,"validation","adjusted_rand_index")),
             modelo_6 = sapply(list_models$model_6,function(x)
               clsf_metrics(x$fit,
                            split_class_b_std,"validation","adjusted_rand_index"))
             )
```

```{r conclusion_6, echo=FALSE}
# carga
resultados <- readRDS(paste0(PATH,"/vignettes/models/res_keras_2.rds"))
colnames(resultados) <- paste("ANN",c("2HL 49/24", "2HL 49/37",
                                      "1HL Sigm 4", "1HL 49",
                                      "3HL 49/24/12", "2HL 49/24 Drop"))
#
resultados %>%
  reshape2::melt() %>%
  ggplot2::ggplot(ggplot2::aes(x = variable, y = value, fill = variable))+
  ggplot2::geom_boxplot() +
  ggplot2::theme_bw() +
  ggplot2::ylab("ARI") +
  ggplot2::xlab("") +
  ggplot2::ggtitle("Comparacion de rendimientos") +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust=1))
```

```{r conclusion_6_1, echo=FALSE}
resultados %>%
  subset(select = -`ANN 1HL Sigm 4`) %>%
  reshape2::melt() %>%
  ggplot2::ggplot(ggplot2::aes(x = variable, y = value, fill = variable))+
  ggplot2::geom_boxplot() +
  ggplot2::theme_bw() +
  ggplot2::ylab("ARI") +
  ggplot2::xlab("") +
  ggplot2::ggtitle("Comparacion de rendimientos") +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust=1))
```

En números, los resultados serían los siguientes

```{r conclusion_7, echo = FALSE}
### Resumenes
data_resumen <- data.frame(Min = unlist(lapply(resultados, min)),
                           Max = unlist(lapply(resultados, max)),
                           Media = unlist(lapply(resultados, mean)),
                           DE = unlist(lapply(resultados, sd)),
                           CV = unlist(
                             lapply(resultados,function(x) 
                               round(100*sd(x)/mean(x),3))))
rownames(data_resumen) <- paste("ANN",c("2HL 49/24", "2HL 49/37",
                                      "1HL Sigm 4", "1HL 49",
                                      "3HL 49/24/12", "2HL 49/24 Drop"))
knitr::kable(data_resumen, digits = 3, row.names = TRUE)
```

##### Micro precision/recall

Se comienza presentando los resultados de precisión por modelo y categoría

````{r conclusion_8, echo=FALSE, eval = FALSE}
# Funcion para crear los resumenes
temp_fun_1 <- function(x,y,rem_name){
  res <- sapply(x,function(z) 
    clsf_metrics(z$fit, split_class_b_std,"validation",rem_name))
  res <- reshape2::melt(res)
  res[,2] <- y
  res[,1] <- gsub(paste0(rem_name,"."),"",res[,1])
  res
}
### Chunk donde se realizan las simulaciones como tal
resultados <- 
  do.call(rbind, list(temp_fun_1(list_models$model_1,"ANN 2HL 49/24","micro_precision"),
                      temp_fun_1(list_models$model_2,"ANN 2HL 49/37","micro_precision"),
                      temp_fun_1(list_models$model_3,"ANN 1HL Sigm 4","micro_precision"),
                      temp_fun_1(list_models$model_4,"ANN 1HL 49","micro_precision"),
                      temp_fun_1(list_models$model_5,"ANN 3HL 49/24/12","micro_precision"),
                      temp_fun_1(list_models$model_6,"ANN 2HL 49/24 Drop","micro_precision")))
```

```{r conclusion_9, echo=FALSE}
# carga
resultados <- readRDS(paste0(PATH,"/vignettes/models/res_keras_3.rds"))
#
resultados$Var1 <- factor(resultados$Var1, 
                          levels = c("Muy bajo","Bajo","Moderado","Alto"))
resultados %>%
  ggplot2::ggplot(ggplot2::aes(x = Var2, y = value, fill = Var1))+
  ggplot2::geom_boxplot() +
  ggplot2::theme_bw() +
  ggplot2::ylab("Precision") +
  ggplot2::xlab("") +
  ggplot2::ggtitle("Comparacion de rendimientos") +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust=1))
```

```{r conclusion_9_1, echo=FALSE}
resultados[resultados$Var2 != "ANN 1HL Sigm 4",] %>%
  ggplot2::ggplot(ggplot2::aes(x = Var2, y = value, fill = Var1))+
  ggplot2::geom_boxplot() +
  ggplot2::theme_bw() +
  ggplot2::ylab("Precision") +
  ggplot2::xlab("") +
  ggplot2::ggtitle("Comparacion de rendimientos") +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust=1))
```

Por su lado, la exhaustividad presenta los siguientes valores

````{r conclusion_10, echo=FALSE, eval = FALSE}
### Chunk donde se realizan las simulaciones como tal
resultados <- 
  do.call(rbind, list(temp_fun_1(list_models$model_1,"ANN 2HL 49/24","micro_recall"),
                      temp_fun_1(list_models$model_2,"ANN 2HL 49/37","micro_recall"),
                      temp_fun_1(list_models$model_3,"ANN 1HL Sigm 4","micro_recall"),
                      temp_fun_1(list_models$model_4,"ANN 1HL 49","micro_recall"),
                      temp_fun_1(list_models$model_5,"ANN 3HL 49/24/12","micro_recall"),
                      temp_fun_1(list_models$model_6,"ANN 2HL 49/24 Drop","micro_recall")))
```

```{r conclusion_11, echo=FALSE}
# carga
resultados <- readRDS(paste0(PATH,"/vignettes/models/res_keras_4.rds"))
#
resultados$Var1 <- factor(resultados$Var1, 
                          levels = c("Muy bajo","Bajo","Moderado","Alto"))
resultados %>%
  ggplot2::ggplot(ggplot2::aes(x = Var2, y = value, fill = Var1))+
  ggplot2::geom_boxplot() +
  ggplot2::theme_bw() +
  ggplot2::ylab("Recall") +
  ggplot2::xlab("") +
  ggplot2::ggtitle("Comparacion de rendimientos") +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust=1))
```

```{r conclusion_11_1, echo=FALSE}
resultados[resultados$Var2 != "ANN 1HL Sigm 4",] %>%
  ggplot2::ggplot(ggplot2::aes(x = Var2, y = value, fill = Var1))+
  ggplot2::geom_boxplot() +
  ggplot2::theme_bw() +
  ggplot2::ylab("Recall") +
  ggplot2::xlab("") +
  ggplot2::ggtitle("Comparacion de rendimientos") +
  ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust=1))  
```
